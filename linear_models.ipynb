{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords\n",
    "from utils import pipeline, calculate_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_regr_params = {\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "bayes_params = {\n",
    "    \"alpha\": [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "def tune_model(model, params, x, y):\n",
    "    clf = GridSearchCV(model, params, cv=10)\n",
    "    clf.fit(x, y)\n",
    "    print('tuned parameters: ', clf.best_params_)\n",
    "    return clf.best_params_\n",
    "\n",
    "def print_metrics(y_true, y_pred):\n",
    "    acc, pre, rec, f1 = calculate_metrics(np.asarray(y_test), np.asarray(y_pred))\n",
    "    return f'accuracy: {acc}; precision: {pre}; recall: {rec}; f1_score: {f1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (512, 326); y_train: 512\n",
      "X_val: (128, 326); y_val: 128\n",
      "X_test: (160, 326); y_test: 160\n",
      "Vocabulary size: 326\n"
     ]
    }
   ],
   "source": [
    "fp_data = \"./op_spam_v1.4/negative_polarity/\"\n",
    "max_features = None  # Maximum vocab size\n",
    "ngram_range = (1, 1)  # Range of n-grams to include in the vocabulary\n",
    "min_df = 0.05  # Minimal document frequency of a word to be included in the vocabulary\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "val_size = 0.2  # Size of the validation set as a percentage of the training set, set to None to disable\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = pipeline(fp_data, max_features, ngram_range, min_df,\n",
    "                                                                        stop_words=stop_words, val_size=val_size)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}; y_train: {len(y_train)}\")\n",
    "print(f\"X_val: {X_val.shape}; y_val: {len(y_val)}\")\n",
    "print(f\"X_test: {X_test.shape}; y_test: {len(y_test)}\")\n",
    "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tuning(model, values: list, param: str):\n",
    "#     model_tune = model\n",
    "#     tuning = GridSearchCV(model_tune, {param:values}, cv=10)\n",
    "#     tuning.fit(X_val, y_val)\n",
    "#     best_param = tuning.best_params_[param]\n",
    "#     print('tuned parameter ', best_param)\n",
    "#     return best_param\n",
    "\n",
    "# def model_creation(model):\n",
    "    \n",
    "#     model.fit(X_train,y_train)\n",
    "#     pred = model.predict(X_test)\n",
    "#     acc, pre, rec, f1 = calculate_metrics(np.asarray(y_test), np.asarray(pred))\n",
    "#     print('accuracy: ', acc, 'precision:', pre, 'recall: ', rec,  'f1_score:', f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned parameters:  {'alpha': 10}\n",
      "tuned model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy: 0.83125; precision: 0.8533333333333334; recall: 0.8; f1_score: 0.8258064516129033'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_params = tune_model(MultinomialNB(), bayes_params, X_train, y_train)\n",
    "\n",
    "print('tuned model')\n",
    "model = MultinomialNB(**tuned_params).fit(X_train, y_train)\n",
    "print_metrics(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned parameters:  {'C': 0.01, 'penalty': 'l2'}\n",
      "tuned model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy: 0.8; precision: 0.8243243243243243; recall: 0.7625; f1_score: 0.7922077922077922'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_params = tune_model(LogisticRegression(random_state=random_state, solver='liblinear'), log_regr_params, X_train, y_train)\n",
    "\n",
    "print('tuned model')                     \n",
    "model = LogisticRegression(random_state=random_state, solver='liblinear', **tuned_params).fit(X_train, y_train)\n",
    "print_metrics(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned parameters:  {'alpha': 1}\n",
      "tuned model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy: 0.8375; precision: 0.8375; recall: 0.8375; f1_score: 0.8375'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_range = (1,2)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = pipeline(fp_data, max_features, ngram_range, min_df,\n",
    "                                                                        stop_words=stop_words, val_size=val_size)\n",
    "\n",
    "tuned_params = tune_model(MultinomialNB(), bayes_params, X_train, y_train)\n",
    "\n",
    "print('tuned model')\n",
    "bay_model = MultinomialNB(**tuned_params).fit(X_train, y_train)\n",
    "print_metrics(y_test, bay_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned parameters:  {'C': 0.01, 'penalty': 'l2'}\n",
      "tuned model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy: 0.79375; precision: 0.8133333333333334; recall: 0.7625; f1_score: 0.7870967741935484'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_params = tune_model(LogisticRegression(random_state=random_state, solver='liblinear'), log_regr_params, X_train, y_train)\n",
    "\n",
    "print('tuned model')                     \n",
    "log_model = LogisticRegression(random_state=random_state, solver='liblinear', **tuned_params).fit(X_train, y_train)\n",
    "print_metrics(y_test, log_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genuine review:  [('location', 0.16240093926252808), ('great', 0.15540009295116428), ('bed', 0.15063790151163126), ('elevator', 0.1438176541048017), ('door', 0.12343650334327459)]\n",
      "\n",
      "Fake review:  [('chicago', -0.2989570972857869), ('seemed', -0.11526175366992326), ('experience', -0.1133431415094073), ('finally', -0.11317218026981682), ('luxury', -0.11218933057781014)]\n"
     ]
    }
   ],
   "source": [
    "# get the coefficients of the model\n",
    "coef = log_model.coef_[0]\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "weighted_features = list(zip(feature_names, coef))\n",
    "\n",
    "print(\"Genuine review: \", sorted(weighted_features, key=lambda x: x[1], reverse=True)[:5])\n",
    "print(\"\\nFake review: \", sorted(weighted_features, key=lambda x: x[1], reverse=False)[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
